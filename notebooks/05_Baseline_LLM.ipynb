{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['type', 'category', 'question', 'best_answer', 'correct_answers', 'incorrect_answers', 'source'],\n",
      "        num_rows: 817\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the TruthfulQA dataset\n",
    "dataset = load_dataset('truthful_qa', 'generation')\n",
    "print(dataset)\n",
    "\n",
    "# Split into train and test sets (80/20 split for example)\n",
    "train_test = dataset['validation'].train_test_split(test_size=0.2)\n",
    "train_dataset = train_test['train']\n",
    "test_dataset = train_test['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0908 17:13:36.289000 28636 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beb3074514a4a1ca9effcbe9f136973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/653 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b34d3cef2a4490b3d4cf3603ac9f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04683972efc4522be5ab6471004cd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/653 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606bc5790fdd49b6b12041346f7e1a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import Dataset\n",
    "\n",
    "# Select GPT-2 small\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token # Set pad token for batching\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Format data for language modeling: question + best answer\n",
    "def format_example(example):\n",
    "    return {'text': f\"Question: {example['question']}\\nAnswer: {example['best_answer']}\"}\n",
    "\n",
    "train_formatted = train_dataset.map(format_example)\n",
    "test_formatted = test_dataset.map(format_example)\n",
    "\n",
    "# Tokenize the formatted text\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "# The remove_columns parameter in map handles removing the original columns.\n",
    "train_tokenized = train_formatted.map(tokenize_function, batched=True, remove_columns=train_formatted.column_names)\n",
    "test_tokenized = test_formatted.map(tokenize_function, batched=True, remove_columns=test_formatted.column_names)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "train_tokenized.set_format(type='torch')\n",
    "test_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [327/327 06:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.163700</td>\n",
       "      <td>2.022361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "C:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the fine-tuned model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model Perplexity: 7.56\n",
      "Saving baseline model to C:/HGC/models/baseline_gpt2_truthfulqa...\n",
      "\n",
      "Baseline establishment complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "# The DataCollator correctly prepares batches for causal language modeling.\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "OUTPUT_DIR = 'C:/HGC/models/baseline_gpt2_truthfulqa'\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # THE FIX: Renamed 'evaluation_strategy' to 'eval_strategy' for your library version\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Instantiate the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print('Starting fine-tuning...')\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "print('\\nEvaluating the fine-tuned model...')\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Calculate and print perplexity\n",
    "perplexity = np.exp(eval_results['eval_loss'])\n",
    "print(f'\\nBaseline Model Perplexity: {perplexity:.2f}')\n",
    "\n",
    "# Save the final model, tokenizer, and results\n",
    "print(f'Saving baseline model to {OUTPUT_DIR}...')\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "results_df = pd.DataFrame([{'model': 'Baseline GPT-2', 'perplexity': perplexity, 'eval_loss': eval_results['eval_loss']}])\n",
    "results_df.to_csv('C:/HGC/data/baseline_results.csv', index=False)\n",
    "print('\\nBaseline establishment complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
